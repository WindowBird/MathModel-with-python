实现思路和流程如下：

数据加载：使用Pandas库加载附件2的数据，得到一个包含所有数据的DataFrame。
数据预处理：对数据进行清洗和处理，包括处理缺失值、将非数值列进行独热编码、提取特征等。
特征工程：通过对数据的探索性分析，提取和分析不同超限的基本特征，如航线、机场等。
模型训练：使用岭回归算法对处理后的数据进行建模，并于线性回归模型做了比较。岭回归是一种正则化线性回归方法，可以在处理多重共线性问题时有效。可以使用Scikit-learn库中的Ridge模型进行训练。
模型评估：使用交叉验证等方法对模型进行评估，评估模型的性能和预测效果。
结果解释：根据训练得到的模型参数和特征重要性，对不同超限的基本特征进行解释和分析，得出结论。



使用岭回归相对于线性回归的优点包括：

解决多重共线性问题：岭回归通过引入正则化项，可以有效处理数据中存在的多重共线性问题，避免模型过于依赖某个特征，提高模型的稳定性和可靠性。
控制模型复杂度：岭回归通过正则化项控制模型的复杂度，可以防止过拟合，提高模型的泛化能力。
对异常值具有鲁棒性：岭回归对异常值的影响较小，能够在存在少量异常值的情况下依然获得较好的拟合效果。
可调节的超参数：岭回归通过调节超参数（正则化强度）来控制模型的拟合效果，可以根据实际情况进行调优。
通过以上实现思路和使用岭回归的方法，可以对附件2中的数据进行分析，研究不同超限的基本特征，如航线、机场等，并得出结论。同时，独热编码和岭回归方法可以在处理非数值列和解决多重共线性问题时提供有效的解决方案，从而得到更稳定和可靠的分析结果。


线性回归结果和岭回归的结果相比孰优孰劣：

根据给出的结果，线性回归的均方误差（MSE）明显较大，为5.8581704657836474e+19，而岭回归的均方误差（MSE）较小，为0.00806745195165686。因此，从评估指标MSE的角度来看，岭回归模型在这个数据集上的表现更好，因为其均方误差较小。

MSE是评估模型预测效果的一种常用指标，其值越小表示模型预测效果越好。在这里，线性回归模型的MSE值较大，说明模型在训练集上的预测效果较差，可能存在过拟合的情况。而岭回归模型的MSE值较小，说明模型在训练集上的预测效果较好，相对来说更具有泛化能力，可以更好地应对新数据的预测。因此，从MSE指标来看，岭回归模型优于线性回归模型。